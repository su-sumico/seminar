page 1

OpenAI CLIP(Contrastive Language-Image Pre-Training) (Source: https://roboflow.com/compare/openai-clip-vs-remoteclip)

* CLIP is an impressive multimodal zero-shot image classifier that achieves impressive results in a wide range of domains with no fine-tuning. It applies the recent advancements in large-scale transformers like GPT-3 to the vision arena.

* Fine tuning CLIP with Remote Sensing (Satellite) images and captions

* Hugging Face: https://huggingface.co/blog/fine-tune-clip-rsicd

Fine-tuned the CLIP Network from OpenAI with satellite images and captions from the RSICD dataset. This dataset consists of about 10,000 images collected from Google Earth, Baidu Map, MapABC, and Tianditu. It is provided freely to the research community to advance remote sensing captioning via Exploring Models and Data for Remote Sensing Image Caption Generation (Lu et al, 2017). The images are (224, 224) RGB images at various resolutions, and each image has up to 5 captions associated with it.

![image](https://github.com/user-attachments/assets/c4e9b7f0-9fd6-4c09-a2d3-a98422e2bafe)

---
page 2

RemoteCLIP (Source: https://github.com/ChenDelong1999/RemoteCLIP)

* RemoteCLIP is a zero-shot classification model for remote sensing.

![image](https://github.com/user-attachments/assets/a7ba0b50-88ab-41c6-a591-07a5511ccf76)
 
---

![image](https://github.com/user-attachments/assets/45b92316-0129-4383-8802-f5b32ab2ad14)

---




